#!/usr/bin/env bun
import { generateText, streamText } from 'ai'
import { openrouter } from '@openrouter/sdk-v4'
import { ensureApiKey } from '@util/check'
import { models } from '@util/models'
import { readFileSync } from 'fs'
import { join } from 'path'

ensureApiKey()

// Use the first model from models array (GPT-4o Mini with image capabilities)
const testModel = models[0]
const imagePath = join(import.meta.dir, 'sample', 'test.jpg')

async function testFileUploadGenerate(): Promise<boolean> {
  try {
    console.log(`\n${'-'.repeat(80)}`)
    console.log(`ü§ñ MODEL: ${testModel.name} (${testModel.slug}) - FILE UPLOAD GENERATE`)
    console.log(`${'-'.repeat(80)}`)
    console.log(`üìÅ FILE: ${imagePath}`)
    console.log(`‚ùì QUESTION: What do you see in this image?`)
    console.log(`${'‚îÄ'.repeat(80)}`)

    // Read image file as buffer
    const imageBuffer = readFileSync(imagePath)

    const result = await generateText({
      model: openrouter(testModel.slug),
      messages: [
        {
          role: 'user',
          content: [
            { 
              type: 'text', 
              text: 'What do you see in this image? Please describe it in detail.' 
            },
            { 
              type: 'image', 
              image: imageBuffer,
              mimeType: 'image/jpeg'
            }
          ]
        }
      ],
      maxTokens: 500,
      temperature: 0.1
    })

    console.log(`üí¨ RESPONSE: ${result.text}`)
    console.log(`${'‚îÄ'.repeat(80)}`)
    console.log(
      `üìä USAGE: ${result.usage.promptTokens} prompt + ${result.usage.completionTokens} completion = ${result.usage.totalTokens} total tokens`
    )

    if (result.finishReason) {
      console.log(`üèÅ FINISH: ${result.finishReason}`)
    }

    console.log(`‚úÖ STATUS: SUCCESS`)
    return true
  } catch (error) {
    console.log(`‚ùå STATUS: FAILED - ${error}`)
    return false
  }
}

async function testFileUploadStream(): Promise<boolean> {
  try {
    console.log(`\n${'-'.repeat(80)}`)
    console.log(`ü§ñ MODEL: ${testModel.name} (${testModel.slug}) - FILE UPLOAD STREAM`)
    console.log(`${'-'.repeat(80)}`)
    console.log(`üìÅ FILE: ${imagePath}`)
    console.log(`‚ùì QUESTION: Analyze this image and tell me about the colors used`)
    console.log(`${'‚îÄ'.repeat(80)}`)

    // Read image file as buffer
    const imageBuffer = readFileSync(imagePath)

    const result = await streamText({
      model: openrouter(testModel.slug),
      messages: [
        {
          role: 'user',
          content: [
            { 
              type: 'text', 
              text: 'Analyze this image and tell me about the colors used in it.' 
            },
            { 
              type: 'image', 
              image: imageBuffer,
              mimeType: 'image/jpeg'
            }
          ]
        }
      ],
      maxTokens: 500,
      temperature: 0.1
    })

    console.log(`üí≠ STREAMING RESPONSE:`)

    // Stream text to console in real-time
    let fullText = ''
    let chunkCount = 0

    for await (const delta of result.textStream) {
      process.stdout.write(delta)
      fullText += delta
      chunkCount++
    }

    console.log(`\nüì¶ CHUNKS: ${chunkCount}`)
    console.log(`\n${'‚îÄ'.repeat(80)}`)

    // Get final results
    const finalResult = await result.response
    const usage = await result.usage
    const finishReason = await result.finishReason

    console.log(
      `üìä USAGE: ${usage.promptTokens} prompt + ${usage.completionTokens} completion = ${usage.totalTokens} total tokens`
    )

    if (finishReason) {
      console.log(`üèÅ FINISH: ${finishReason}`)
    }

    console.log(`‚úÖ STATUS: SUCCESS`)
    return true
  } catch (error) {
    console.log(`‚ùå STATUS: FAILED - ${error}`)
    return false
  }
}

async function runFileUploadTests() {
  console.log('üìÅ OpenRouter AI SDK v4 - File Upload Tests')
  console.log('-'.repeat(50))
  console.log(`üñºÔ∏è  Testing with image: ${imagePath}`)
  console.log(`ü§ñ Using model: ${testModel.name} (${testModel.slug})`)

  const results: {
    generate: boolean
    stream: boolean
  } = {
    generate: false,
    stream: false
  }

  // Test generateText with file upload
  results.generate = await testFileUploadGenerate()

  // Small delay between tests
  await new Promise((resolve) => setTimeout(resolve, 2000))

  // Test streamText with file upload
  results.stream = await testFileUploadStream()

  console.log('\nüìà File Upload Test Results Summary')
  console.log('-'.repeat(50))

  const generateStatus = results.generate ? '‚úÖ' : '‚ùå'
  const streamStatus = results.stream ? '‚úÖ' : '‚ùå'

  console.log(`${testModel.name}: Generate ${generateStatus} | Stream ${streamStatus}`)

  const totalTests = 2
  const passedTests = (results.generate ? 1 : 0) + (results.stream ? 1 : 0)

  console.log(
    `\nüéØ Overall: ${passedTests}/${totalTests} file upload tests passed (${Math.round((passedTests / totalTests) * 100)}%)`
  )

  if (passedTests === totalTests) {
    console.log('üéâ All file upload tests passed!')
    process.exit(0)
  } else {
    console.log('‚ö†Ô∏è  Some file upload tests failed. Check the output above for details.')
    process.exit(1)
  }
}

// Error handling
process.on('uncaughtException', (error) => {
  console.error('üí• Uncaught Exception:', error)
  process.exit(1)
})

process.on('unhandledRejection', (error) => {
  console.error('üí• Unhandled Rejection:', error)
  process.exit(1)
})

// Run the tests
if (import.meta.main) {
  runFileUploadTests().catch((error) => {
    console.error('üí• Fatal error:', error)
    process.exit(1)
  })
}

export { testFileUploadGenerate, testFileUploadStream }